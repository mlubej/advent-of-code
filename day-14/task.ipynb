{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "test_data = open('input-test.txt').read()\n",
    "data = open('input.txt').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "content = test_data\n",
    "\n",
    "def parse_input(content):\n",
    "    template, insertion_rules = content.split('\\n\\n')\n",
    "    insertion_rules = dict(re.findall('([A-Z]+) -> ([A-Z]+)', insertion_rules))\n",
    "    return template, insertion_rules\n",
    "\n",
    "\n",
    "def find_matches(element, substitute, template):\n",
    "    matches = []\n",
    "    for idx in range(len(template)):\n",
    "        if ''.join(template[idx:idx+2]) == element:\n",
    "            matches.append((substitute, idx))\n",
    "    \n",
    "    return matches\n",
    "\n",
    "\n",
    "def polymerize(content, n_steps = 1):\n",
    "    template, insertion_rules = parse_input(content)\n",
    "\n",
    "    while n_steps > 0:\n",
    "        matches = []\n",
    "        for k, v in insertion_rules.items():\n",
    "            matches.extend(find_matches(k, v, template))\n",
    "\n",
    "        matches = sorted(matches, key=lambda x: -x[1])\n",
    "\n",
    "        template = np.array(list(template))\n",
    "        for sub, idx in matches:\n",
    "            template = np.insert(template, idx+1, sub)\n",
    "\n",
    "        template = ''.join(template)\n",
    "        n_steps -= 1\n",
    "\n",
    "    return template\n",
    "\n",
    "\n",
    "def extract_result(polymer):\n",
    "    _, counts = np.unique(list(polymer), return_counts=True)\n",
    "    return max(counts) - min(counts)\n",
    "\n",
    "\n",
    "assert polymerize(content, 1) == 'NCNBCHB'\n",
    "assert polymerize(content, 2) == 'NBCCNBBBCBHCB'\n",
    "assert polymerize(content, 3) == 'NBBBCNCCNBBNBNBBCHBHHBCHB'\n",
    "assert polymerize(content, 4) == 'NBBNBNBBCCNBCNCCNBBNBBNBBBNBBNBBCBHCBHHNHCBBCBHCB'\n",
    "assert extract_result(polymerize(content, 10)) == 1588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2703"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real\n",
    "content = data\n",
    "extract_result(polymerize(content, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "content = test_data\n",
    "\n",
    "def get_pairs(template):\n",
    "    return [''.join(template[idx:idx+2]) for idx in range(len(template)-1)]\n",
    "\n",
    "\n",
    "def get_pair_counts(template):\n",
    "    pairs = get_pairs(template)\n",
    "    return {pair: len(find_matches(pair, None, template)) for pair in pairs}\n",
    "\n",
    "\n",
    "def extract_result_fast(content, n_steps = 1):\n",
    "    template, insertion_rules = parse_input(content)\n",
    "\n",
    "    pairs = get_pairs(template)\n",
    "    pair_counts = {pair: len(find_matches(pair, None, template)) for pair in pairs}\n",
    "    el_counts = {k: int(v) for (k, v) in np.transpose(np.unique(list(template), return_counts=True))}\n",
    "\n",
    "    while n_steps > 0:\n",
    "\n",
    "        occurrences = {el: pair_counts[el] for el, _ in insertion_rules.items() if el in pair_counts}\n",
    "        for el, count in occurrences.items(): \n",
    "            del pair_counts[el]\n",
    "\n",
    "        for el, count in occurrences.items(): \n",
    "            sub = insertion_rules[el]\n",
    "            el_counts[sub] = 0 if sub not in el_counts else el_counts[sub]\n",
    "            el_counts[sub] += count\n",
    "            new_elements = [f'{el[0]}{sub}', f'{sub}{el[1]}']\n",
    "            for new_el in new_elements:\n",
    "                pair_counts[new_el] = 0 if new_el not in pair_counts else pair_counts[new_el]\n",
    "                pair_counts[new_el] += count\n",
    "                \n",
    "        n_steps -= 1\n",
    "\n",
    "    return max(el_counts.values()) - min(el_counts.values())\n",
    "\n",
    "assert extract_result_fast(content, 10) == 1588\n",
    "assert extract_result_fast(content, 40) == 2188189693529"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2984946368465"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "content = data\n",
    "extract_result_fast(content, 40)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "397440ca27dd4f2db3754d30213d67198d7f32c89d82a8ff28a1eadbf5e56d70"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit ('advent': pyenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
